{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2b584157a8c40488de28cdb5dee5af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be80c311402e42798c0de7a895772bce",
              "IPY_MODEL_f2cdd37a407141f98027eb9d08e40101",
              "IPY_MODEL_2297e9cddd6b445ebd41db219d411718"
            ],
            "layout": "IPY_MODEL_43e2248a3eac47388eb0a1369b9494b4"
          }
        },
        "be80c311402e42798c0de7a895772bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8408c61e22cd472f931e0020ea93e76a",
            "placeholder": "​",
            "style": "IPY_MODEL_11577b9b6c07463d837a78845d74b4d5",
            "value": "100%"
          }
        },
        "f2cdd37a407141f98027eb9d08e40101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_886cf06553cc4c6fa99dc64b192b138b",
            "max": 9335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02da916324904382ac305adf787fc70c",
            "value": 9335
          }
        },
        "2297e9cddd6b445ebd41db219d411718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e605200cd394d17b0251d3717dac6d9",
            "placeholder": "​",
            "style": "IPY_MODEL_9441e7b8c6ff4a7eb13da187a8b267ea",
            "value": " 9335/9335 [00:00&lt;00:00, 14342.89it/s]"
          }
        },
        "43e2248a3eac47388eb0a1369b9494b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8408c61e22cd472f931e0020ea93e76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11577b9b6c07463d837a78845d74b4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "886cf06553cc4c6fa99dc64b192b138b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02da916324904382ac305adf787fc70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e605200cd394d17b0251d3717dac6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9441e7b8c6ff4a7eb13da187a8b267ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5bP_azCdH8k",
        "outputId": "06cbcdc7-0b75-41a9-c6ae-f1b502132d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  1 15:09:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xOV6Ir6AMQi",
        "outputId": "011b09a7-4a8a-4adb-8437-bea186d07392"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/390.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.22.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.10.1)\n",
            "Collecting torch<2.0,>=1.2 (from pytorch-tabnet)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.6.3)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.0,>=1.2->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.0,>=1.2->pytorch-tabnet)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.0,>=1.2->pytorch-tabnet)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.0,>=1.2->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.2->pytorch-tabnet) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.2->pytorch-tabnet) (0.40.0)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, pytorch-tabnet\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pytorch-tabnet-4.0 torch-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier"
      ],
      "metadata": {
        "id": "THDjcn6ilhvM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "chart_df = pd.read_csv(\"/content/drive/MyDrive/chart_with_sentiment_scores.csv\")"
      ],
      "metadata": {
        "id": "pbpEV9qld4Zj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add technical indicators\n",
        "import pandas_ta as ta\n",
        "from tqdm.auto import tqdm\n",
        "hours, days, months = [], [], []\n",
        "for dt in tqdm(chart_df[\"datetime\"]):\n",
        "  dtobj = pd.to_datetime(dt)\n",
        "  hours.append(dtobj.hour)\n",
        "  days.append(dtobj.day)\n",
        "  months.append(dtobj.month)\n",
        "\n",
        "chart_df[\"hours\"] = hours\n",
        "chart_df[\"days\"] = days\n",
        "chart_df[\"months\"] = months\n",
        "\n",
        "chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False)\n",
        "chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False)\n",
        "chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False)\n",
        "chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100.0\n",
        "chart_df[\"hwma\"] = chart_df.ta.hwma(lookahead=False)\n",
        "chart_df[\"linreg\"] = chart_df.ta.linreg(lookahead=False)\n",
        "chart_df[\"hwma/close\"] = chart_df[\"hwma\"] / chart_df[\"close\"]\n",
        "chart_df[\"linreg/close\"] = chart_df[\"linreg\"] / chart_df[\"close\"]\n",
        "chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"]\n",
        "chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"]\n",
        "chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"]\n",
        "chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"]\n",
        "chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"]\n",
        "chart_df[\"low/close\"]  = chart_df[\"low\"] / chart_df[\"close\"]\n",
        "\n",
        "for l in range(1, 6):\n",
        "  for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
        "    val = chart_df[col].values\n",
        "    val_ret = [None for _ in range(l)]\n",
        "    for i in range(l, len(val)):\n",
        "      if val[i-l] == 0:\n",
        "        ret = 1\n",
        "      else:\n",
        "        ret = val[i] / val[i-l]\n",
        "      val_ret.append(ret)\n",
        "    chart_df[f\"{col}_change_{l}\"] = val_ret\n",
        "\n",
        "chart_df = chart_df.drop(columns={\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"linreg\", \"hwma\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d2b584157a8c40488de28cdb5dee5af2",
            "be80c311402e42798c0de7a895772bce",
            "f2cdd37a407141f98027eb9d08e40101",
            "2297e9cddd6b445ebd41db219d411718",
            "43e2248a3eac47388eb0a1369b9494b4",
            "8408c61e22cd472f931e0020ea93e76a",
            "11577b9b6c07463d837a78845d74b4d5",
            "886cf06553cc4c6fa99dc64b192b138b",
            "02da916324904382ac305adf787fc70c",
            "8e605200cd394d17b0251d3717dac6d9",
            "9441e7b8c6ff4a7eb13da187a8b267ea"
          ]
        },
        "id": "YrOupxpFeCIb",
        "outputId": "59ac5c83-9f88-402d-e7be-93eb3c122f79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9335 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2b584157a8c40488de28cdb5dee5af2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chart_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "yhiKYZapeWum"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chart_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nhuw5iBdeY_9",
        "outputId": "69e6a2f8-f13c-4005-d67f-5597604d7daa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    targets  news_positive_scores  news_negative_scores  hours  days  months  \\\n",
              "39      2.0              0.000000              0.000000      4     1       4   \n",
              "40      2.0              0.000000              0.000000      8     1       4   \n",
              "41      2.0             13.904989              8.095011     12     1       4   \n",
              "42      2.0              8.305100              3.694901     16     1       4   \n",
              "43      0.0              8.310017              6.689983     20     1       4   \n",
              "\n",
              "        ebsw       cmf       bop   rsi/100  ...  open_change_4  high_change_4  \\\n",
              "39  0.000000  0.221446 -0.045573  0.659537  ...       1.004453       1.007434   \n",
              "40  0.577350  0.201553 -0.005917  0.658919  ...       1.007774       1.006996   \n",
              "41  0.796874  0.172388  0.514761  0.690842  ...       1.005480       1.011357   \n",
              "42  0.983671  0.021719 -0.328696  0.659900  ...       1.010377       1.003634   \n",
              "43  0.986626  0.075315  0.291923  0.674547  ...       1.002053       1.002638   \n",
              "\n",
              "    low_change_4  close_change_4  volume_change_4  open_change_5  \\\n",
              "39      1.006192        1.007774         1.143676       1.010897   \n",
              "40      1.003691        1.005484         1.730719       1.004198   \n",
              "41      1.006952        1.010020         3.140040       1.007732   \n",
              "42      1.016228        1.001828         0.437554       1.009456   \n",
              "43      1.003106        1.003805         0.600674       1.008761   \n",
              "\n",
              "    high_change_5  low_change_5  close_change_5  volume_change_5  \n",
              "39       1.006783      1.008813        1.004198         1.477008  \n",
              "40       1.006005      1.003780        1.007735         1.223106  \n",
              "41       1.011994      1.007534        1.009474         2.201117  \n",
              "42       1.010700      1.008450        1.008163         2.220246  \n",
              "43       1.003386      1.016425        1.003550         0.273292  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d43666e7-4564-49ac-a76e-a3808f7eb0bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>news_positive_scores</th>\n",
              "      <th>news_negative_scores</th>\n",
              "      <th>hours</th>\n",
              "      <th>days</th>\n",
              "      <th>months</th>\n",
              "      <th>ebsw</th>\n",
              "      <th>cmf</th>\n",
              "      <th>bop</th>\n",
              "      <th>rsi/100</th>\n",
              "      <th>...</th>\n",
              "      <th>open_change_4</th>\n",
              "      <th>high_change_4</th>\n",
              "      <th>low_change_4</th>\n",
              "      <th>close_change_4</th>\n",
              "      <th>volume_change_4</th>\n",
              "      <th>open_change_5</th>\n",
              "      <th>high_change_5</th>\n",
              "      <th>low_change_5</th>\n",
              "      <th>close_change_5</th>\n",
              "      <th>volume_change_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.221446</td>\n",
              "      <td>-0.045573</td>\n",
              "      <td>0.659537</td>\n",
              "      <td>...</td>\n",
              "      <td>1.004453</td>\n",
              "      <td>1.007434</td>\n",
              "      <td>1.006192</td>\n",
              "      <td>1.007774</td>\n",
              "      <td>1.143676</td>\n",
              "      <td>1.010897</td>\n",
              "      <td>1.006783</td>\n",
              "      <td>1.008813</td>\n",
              "      <td>1.004198</td>\n",
              "      <td>1.477008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.201553</td>\n",
              "      <td>-0.005917</td>\n",
              "      <td>0.658919</td>\n",
              "      <td>...</td>\n",
              "      <td>1.007774</td>\n",
              "      <td>1.006996</td>\n",
              "      <td>1.003691</td>\n",
              "      <td>1.005484</td>\n",
              "      <td>1.730719</td>\n",
              "      <td>1.004198</td>\n",
              "      <td>1.006005</td>\n",
              "      <td>1.003780</td>\n",
              "      <td>1.007735</td>\n",
              "      <td>1.223106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2.0</td>\n",
              "      <td>13.904989</td>\n",
              "      <td>8.095011</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.796874</td>\n",
              "      <td>0.172388</td>\n",
              "      <td>0.514761</td>\n",
              "      <td>0.690842</td>\n",
              "      <td>...</td>\n",
              "      <td>1.005480</td>\n",
              "      <td>1.011357</td>\n",
              "      <td>1.006952</td>\n",
              "      <td>1.010020</td>\n",
              "      <td>3.140040</td>\n",
              "      <td>1.007732</td>\n",
              "      <td>1.011994</td>\n",
              "      <td>1.007534</td>\n",
              "      <td>1.009474</td>\n",
              "      <td>2.201117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.305100</td>\n",
              "      <td>3.694901</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.983671</td>\n",
              "      <td>0.021719</td>\n",
              "      <td>-0.328696</td>\n",
              "      <td>0.659900</td>\n",
              "      <td>...</td>\n",
              "      <td>1.010377</td>\n",
              "      <td>1.003634</td>\n",
              "      <td>1.016228</td>\n",
              "      <td>1.001828</td>\n",
              "      <td>0.437554</td>\n",
              "      <td>1.009456</td>\n",
              "      <td>1.010700</td>\n",
              "      <td>1.008450</td>\n",
              "      <td>1.008163</td>\n",
              "      <td>2.220246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8.310017</td>\n",
              "      <td>6.689983</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.986626</td>\n",
              "      <td>0.075315</td>\n",
              "      <td>0.291923</td>\n",
              "      <td>0.674547</td>\n",
              "      <td>...</td>\n",
              "      <td>1.002053</td>\n",
              "      <td>1.002638</td>\n",
              "      <td>1.003106</td>\n",
              "      <td>1.003805</td>\n",
              "      <td>0.600674</td>\n",
              "      <td>1.008761</td>\n",
              "      <td>1.003386</td>\n",
              "      <td>1.016425</td>\n",
              "      <td>1.003550</td>\n",
              "      <td>0.273292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d43666e7-4564-49ac-a76e-a3808f7eb0bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d43666e7-4564-49ac-a76e-a3808f7eb0bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d43666e7-4564-49ac-a76e-a3808f7eb0bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_columns = []\n",
        "\n",
        "for col in chart_df.columns:\n",
        "  if col != \"targets\":\n",
        "    train_columns.append(col)\n",
        "\n",
        "X = chart_df[train_columns]\n",
        "Y = chart_df[\"targets\"]"
      ],
      "metadata": {
        "id": "RGeQMTrreaae"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUm2gQTThNZ3",
        "outputId": "544ef57d-8579-41a0-f29f-2990f13d4b6c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9296, 42), (9296,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Disable all user warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "4iAYxAsgebns"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  n_d = trial.suggest_categorical(\"n_d\", [8, 16, 32])\n",
        "  n_a = trial.suggest_categorical(\"n_a\", [8, 16, 32])\n",
        "  n_steps = trial.suggest_categorical(\"n_steps\", [3, 4, 5])\n",
        "  gamma = trial.suggest_float(\"gamma\", 1.0, 2.0)\n",
        "  mask_type = trial.suggest_categorical(\"mask_type\", [\"sparsemax\", \"entmax\"])\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "  max_epochs = trial.suggest_int(\"max_epochs\", 50, 200)\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  accuracies = []\n",
        "  for train_idx, val_idx in tscv.split(X):\n",
        "    X_train, X_val = X.iloc[train_idx].values, X.iloc[val_idx].values\n",
        "    Y_train, Y_val = Y.iloc[train_idx].values, Y.iloc[val_idx].values\n",
        "    model = TabNetClassifier(\n",
        "        n_d=n_d,\n",
        "        n_a=n_a,\n",
        "        n_steps=n_steps,\n",
        "        gamma=gamma,\n",
        "        optimizer_fn=optim.Adam,\n",
        "        optimizer_params=dict(lr=1e-3),\n",
        "        mask_type=mask_type,\n",
        "        device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        verbose=0 # do not print training logs\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train = X_train,\n",
        "        y_train = Y_train,\n",
        "        eval_set = [(X_val, Y_val)],\n",
        "        eval_metric = [\"balanced_accuracy\"],\n",
        "        patience = 100,\n",
        "        batch_size=batch_size,\n",
        "        virtual_batch_size = batch_size,\n",
        "        num_workers = 0,\n",
        "        max_epochs=max_epochs,\n",
        "        drop_last = False\n",
        "    )\n",
        "    Y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(Y_val, Y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "  return sum(accuracies) / len(accuracies)\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shDPQw4ffE1m",
        "outputId": "998661d4-271b-47c8-d300-63c8571ac407"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 15:22:26,170] A new study created in memory with name: no-name-2dcaf147-3f8e-43e4-b7be-e3cbfed4d012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 166 with best_epoch = 122 and best_val_0_balanced_accuracy = 0.4375\n",
            "Stop training because you reached max_epochs = 166 with best_epoch = 86 and best_val_0_balanced_accuracy = 0.53553\n",
            "\n",
            "Early stopping occurred at epoch 142 with best_epoch = 42 and best_val_0_balanced_accuracy = 0.39699\n",
            "Stop training because you reached max_epochs = 166 with best_epoch = 158 and best_val_0_balanced_accuracy = 0.43695\n",
            "\n",
            "Early stopping occurred at epoch 161 with best_epoch = 61 and best_val_0_balanced_accuracy = 0.45854\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 15:35:32,173] Trial 0 finished with value: 0.45668173014848285 and parameters: {'n_d': 32, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5331732720751277, 'mask_type': 'entmax', 'batch_size': 128, 'max_epochs': 166}. Best is trial 0 with value: 0.45668173014848285.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 141 with best_epoch = 51 and best_val_0_balanced_accuracy = 0.44827\n",
            "Stop training because you reached max_epochs = 141 with best_epoch = 110 and best_val_0_balanced_accuracy = 0.5451\n",
            "\n",
            "Early stopping occurred at epoch 132 with best_epoch = 32 and best_val_0_balanced_accuracy = 0.40614\n",
            "Stop training because you reached max_epochs = 141 with best_epoch = 134 and best_val_0_balanced_accuracy = 0.4515\n",
            "Stop training because you reached max_epochs = 141 with best_epoch = 78 and best_val_0_balanced_accuracy = 0.46857\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 16:29:05,732] Trial 1 finished with value: 0.4565526145900581 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 4, 'gamma': 1.923618395436067, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 141}. Best is trial 0 with value: 0.45668173014848285.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 73 with best_epoch = 49 and best_val_0_balanced_accuracy = 0.43156\n",
            "Stop training because you reached max_epochs = 73 with best_epoch = 66 and best_val_0_balanced_accuracy = 0.50133\n",
            "Stop training because you reached max_epochs = 73 with best_epoch = 41 and best_val_0_balanced_accuracy = 0.40851\n",
            "Stop training because you reached max_epochs = 73 with best_epoch = 68 and best_val_0_balanced_accuracy = 0.44492\n",
            "Stop training because you reached max_epochs = 73 with best_epoch = 25 and best_val_0_balanced_accuracy = 0.44957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 16:43:25,866] Trial 2 finished with value: 0.43008392511297605 and parameters: {'n_d': 8, 'n_a': 8, 'n_steps': 4, 'gamma': 1.9219378726137601, 'mask_type': 'entmax', 'batch_size': 64, 'max_epochs': 73}. Best is trial 0 with value: 0.45668173014848285.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 124 with best_epoch = 108 and best_val_0_balanced_accuracy = 0.43965\n",
            "Stop training because you reached max_epochs = 124 with best_epoch = 66 and best_val_0_balanced_accuracy = 0.50997\n",
            "Stop training because you reached max_epochs = 124 with best_epoch = 107 and best_val_0_balanced_accuracy = 0.38594\n",
            "Stop training because you reached max_epochs = 124 with best_epoch = 54 and best_val_0_balanced_accuracy = 0.44466\n",
            "Stop training because you reached max_epochs = 124 with best_epoch = 74 and best_val_0_balanced_accuracy = 0.46247\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 16:58:26,235] Trial 3 finished with value: 0.4552614590058102 and parameters: {'n_d': 8, 'n_a': 16, 'n_steps': 5, 'gamma': 1.1504433884546272, 'mask_type': 'sparsemax', 'batch_size': 128, 'max_epochs': 124}. Best is trial 0 with value: 0.45668173014848285.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 107 with best_epoch = 89 and best_val_0_balanced_accuracy = 0.4664\n",
            "Stop training because you reached max_epochs = 107 with best_epoch = 93 and best_val_0_balanced_accuracy = 0.53494\n",
            "Stop training because you reached max_epochs = 107 with best_epoch = 20 and best_val_0_balanced_accuracy = 0.41282\n",
            "Stop training because you reached max_epochs = 107 with best_epoch = 93 and best_val_0_balanced_accuracy = 0.44893\n",
            "Stop training because you reached max_epochs = 107 with best_epoch = 106 and best_val_0_balanced_accuracy = 0.45911\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 17:15:10,750] Trial 4 finished with value: 0.46016785022595225 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.013373276722331, 'mask_type': 'sparsemax', 'batch_size': 64, 'max_epochs': 107}. Best is trial 4 with value: 0.46016785022595225.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 160 with best_epoch = 142 and best_val_0_balanced_accuracy = 0.46686\n",
            "Stop training because you reached max_epochs = 160 with best_epoch = 75 and best_val_0_balanced_accuracy = 0.53146\n",
            "\n",
            "Early stopping occurred at epoch 125 with best_epoch = 25 and best_val_0_balanced_accuracy = 0.41466\n",
            "\n",
            "Early stopping occurred at epoch 137 with best_epoch = 37 and best_val_0_balanced_accuracy = 0.43884\n",
            "Stop training because you reached max_epochs = 160 with best_epoch = 123 and best_val_0_balanced_accuracy = 0.46353\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 18:23:42,181] Trial 5 finished with value: 0.4405422853453841 and parameters: {'n_d': 32, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5279286702277235, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 160}. Best is trial 4 with value: 0.46016785022595225.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 123 with best_epoch = 106 and best_val_0_balanced_accuracy = 0.45848\n",
            "Stop training because you reached max_epochs = 123 with best_epoch = 119 and best_val_0_balanced_accuracy = 0.54335\n",
            "Stop training because you reached max_epochs = 123 with best_epoch = 51 and best_val_0_balanced_accuracy = 0.40208\n",
            "Stop training because you reached max_epochs = 123 with best_epoch = 110 and best_val_0_balanced_accuracy = 0.44792\n",
            "Stop training because you reached max_epochs = 123 with best_epoch = 103 and best_val_0_balanced_accuracy = 0.47156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 19:22:35,135] Trial 6 finished with value: 0.4606843124596514 and parameters: {'n_d': 8, 'n_a': 8, 'n_steps': 5, 'gamma': 1.0798710488664776, 'mask_type': 'entmax', 'batch_size': 32, 'max_epochs': 123}. Best is trial 6 with value: 0.4606843124596514.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 140 with best_epoch = 75 and best_val_0_balanced_accuracy = 0.44715\n",
            "Stop training because you reached max_epochs = 140 with best_epoch = 84 and best_val_0_balanced_accuracy = 0.54925\n",
            "Stop training because you reached max_epochs = 140 with best_epoch = 79 and best_val_0_balanced_accuracy = 0.39622\n",
            "Stop training because you reached max_epochs = 140 with best_epoch = 107 and best_val_0_balanced_accuracy = 0.45419\n",
            "Stop training because you reached max_epochs = 140 with best_epoch = 134 and best_val_0_balanced_accuracy = 0.46319\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 19:50:46,597] Trial 7 finished with value: 0.45422853453841194 and parameters: {'n_d': 8, 'n_a': 8, 'n_steps': 4, 'gamma': 1.5173601623875008, 'mask_type': 'entmax', 'batch_size': 64, 'max_epochs': 140}. Best is trial 6 with value: 0.4606843124596514.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 174 with best_epoch = 121 and best_val_0_balanced_accuracy = 0.45674\n",
            "Stop training because you reached max_epochs = 174 with best_epoch = 153 and best_val_0_balanced_accuracy = 0.54202\n",
            "Stop training because you reached max_epochs = 174 with best_epoch = 101 and best_val_0_balanced_accuracy = 0.40376\n",
            "Stop training because you reached max_epochs = 174 with best_epoch = 105 and best_val_0_balanced_accuracy = 0.44044\n",
            "Stop training because you reached max_epochs = 174 with best_epoch = 115 and best_val_0_balanced_accuracy = 0.47978\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 20:45:31,672] Trial 8 finished with value: 0.46765655261459005 and parameters: {'n_d': 8, 'n_a': 16, 'n_steps': 3, 'gamma': 1.124011601626289, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 174}. Best is trial 8 with value: 0.46765655261459005.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 121 with best_epoch = 119 and best_val_0_balanced_accuracy = 0.40494\n",
            "Stop training because you reached max_epochs = 121 with best_epoch = 117 and best_val_0_balanced_accuracy = 0.5178\n",
            "Stop training because you reached max_epochs = 121 with best_epoch = 96 and best_val_0_balanced_accuracy = 0.40607\n",
            "Stop training because you reached max_epochs = 121 with best_epoch = 55 and best_val_0_balanced_accuracy = 0.44195\n",
            "Stop training because you reached max_epochs = 121 with best_epoch = 116 and best_val_0_balanced_accuracy = 0.46834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 20:55:38,471] Trial 9 finished with value: 0.4521626856036153 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 3, 'gamma': 1.9505036093309873, 'mask_type': 'sparsemax', 'batch_size': 128, 'max_epochs': 121}. Best is trial 8 with value: 0.46765655261459005.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 197 with best_epoch = 124 and best_val_0_balanced_accuracy = 0.45894\n",
            "Stop training because you reached max_epochs = 197 with best_epoch = 177 and best_val_0_balanced_accuracy = 0.54304\n",
            "Stop training because you reached max_epochs = 197 with best_epoch = 172 and best_val_0_balanced_accuracy = 0.42513\n",
            "\n",
            "Early stopping occurred at epoch 145 with best_epoch = 45 and best_val_0_balanced_accuracy = 0.45753\n",
            "Stop training because you reached max_epochs = 197 with best_epoch = 136 and best_val_0_balanced_accuracy = 0.47253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 21:53:41,058] Trial 10 finished with value: 0.46649451258876684 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.2676520645185383, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 197}. Best is trial 8 with value: 0.46765655261459005.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 190 with best_epoch = 90 and best_val_0_balanced_accuracy = 0.46253\n",
            "Stop training because you reached max_epochs = 200 with best_epoch = 177 and best_val_0_balanced_accuracy = 0.52963\n",
            "Stop training because you reached max_epochs = 200 with best_epoch = 171 and best_val_0_balanced_accuracy = 0.42777\n",
            "\n",
            "Early stopping occurred at epoch 164 with best_epoch = 64 and best_val_0_balanced_accuracy = 0.45044\n",
            "Stop training because you reached max_epochs = 200 with best_epoch = 106 and best_val_0_balanced_accuracy = 0.45993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 22:53:45,838] Trial 11 finished with value: 0.4623628147191736 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.2595395250376367, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 200}. Best is trial 8 with value: 0.46765655261459005.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 197 with best_epoch = 142 and best_val_0_balanced_accuracy = 0.47894\n",
            "Stop training because you reached max_epochs = 197 with best_epoch = 155 and best_val_0_balanced_accuracy = 0.55649\n",
            "\n",
            "Early stopping occurred at epoch 185 with best_epoch = 85 and best_val_0_balanced_accuracy = 0.40115\n",
            "\n",
            "Early stopping occurred at epoch 164 with best_epoch = 64 and best_val_0_balanced_accuracy = 0.45603\n",
            "\n",
            "Early stopping occurred at epoch 180 with best_epoch = 80 and best_val_0_balanced_accuracy = 0.46315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-01 23:51:05,890] Trial 12 finished with value: 0.4729502905100064 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.2691170857851946, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 197}. Best is trial 12 with value: 0.4729502905100064.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 178 with best_epoch = 143 and best_val_0_balanced_accuracy = 0.47855\n",
            "Stop training because you reached max_epochs = 178 with best_epoch = 124 and best_val_0_balanced_accuracy = 0.55938\n",
            "\n",
            "Early stopping occurred at epoch 142 with best_epoch = 42 and best_val_0_balanced_accuracy = 0.40724\n",
            "\n",
            "Early stopping occurred at epoch 157 with best_epoch = 57 and best_val_0_balanced_accuracy = 0.44575\n",
            "Stop training because you reached max_epochs = 178 with best_epoch = 94 and best_val_0_balanced_accuracy = 0.47749\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 00:42:56,970] Trial 13 finished with value: 0.4721755971594577 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.3086693553639435, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 178}. Best is trial 12 with value: 0.4729502905100064.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 185 with best_epoch = 133 and best_val_0_balanced_accuracy = 0.47416\n",
            "Stop training because you reached max_epochs = 185 with best_epoch = 167 and best_val_0_balanced_accuracy = 0.53982\n",
            "Stop training because you reached max_epochs = 185 with best_epoch = 180 and best_val_0_balanced_accuracy = 0.41876\n",
            "\n",
            "Early stopping occurred at epoch 176 with best_epoch = 76 and best_val_0_balanced_accuracy = 0.44389\n",
            "Stop training because you reached max_epochs = 185 with best_epoch = 130 and best_val_0_balanced_accuracy = 0.48239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 01:39:55,165] Trial 14 finished with value: 0.4725629438347321 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.363285275973115, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 185}. Best is trial 12 with value: 0.4729502905100064.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 187 with best_epoch = 169 and best_val_0_balanced_accuracy = 0.47474\n",
            "Stop training because you reached max_epochs = 187 with best_epoch = 118 and best_val_0_balanced_accuracy = 0.54893\n",
            "Stop training because you reached max_epochs = 187 with best_epoch = 153 and best_val_0_balanced_accuracy = 0.42702\n",
            "Stop training because you reached max_epochs = 187 with best_epoch = 131 and best_val_0_balanced_accuracy = 0.46275\n",
            "Stop training because you reached max_epochs = 187 with best_epoch = 120 and best_val_0_balanced_accuracy = 0.46822\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 02:38:12,183] Trial 15 finished with value: 0.48160103292446743 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.3776893571377133, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 187}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 83 with best_epoch = 76 and best_val_0_balanced_accuracy = 0.44714\n",
            "Stop training because you reached max_epochs = 83 with best_epoch = 43 and best_val_0_balanced_accuracy = 0.53444\n",
            "Stop training because you reached max_epochs = 83 with best_epoch = 68 and best_val_0_balanced_accuracy = 0.40515\n",
            "Stop training because you reached max_epochs = 83 with best_epoch = 75 and best_val_0_balanced_accuracy = 0.44759\n",
            "Stop training because you reached max_epochs = 83 with best_epoch = 63 and best_val_0_balanced_accuracy = 0.4683\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 03:04:19,495] Trial 16 finished with value: 0.45577792123950933 and parameters: {'n_d': 16, 'n_a': 32, 'n_steps': 3, 'gamma': 1.4079528606179081, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 83}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_balanced_accuracy = 0.43276\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_balanced_accuracy = 0.52467\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 42 and best_val_0_balanced_accuracy = 0.40904\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 45 and best_val_0_balanced_accuracy = 0.45355\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 48 and best_val_0_balanced_accuracy = 0.46062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 03:20:03,199] Trial 17 finished with value: 0.45112976113621694 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.6314430924106442, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 50}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 141 with best_epoch = 41 and best_val_0_balanced_accuracy = 0.43555\n",
            "Stop training because you reached max_epochs = 156 with best_epoch = 151 and best_val_0_balanced_accuracy = 0.54259\n",
            "\n",
            "Early stopping occurred at epoch 113 with best_epoch = 13 and best_val_0_balanced_accuracy = 0.41244\n",
            "Stop training because you reached max_epochs = 156 with best_epoch = 135 and best_val_0_balanced_accuracy = 0.46356\n",
            "Stop training because you reached max_epochs = 156 with best_epoch = 131 and best_val_0_balanced_accuracy = 0.47711\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 03:55:10,353] Trial 18 finished with value: 0.4446739832149774 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 5, 'gamma': 1.1862651878489272, 'mask_type': 'entmax', 'batch_size': 64, 'max_epochs': 156}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 189 with best_epoch = 145 and best_val_0_balanced_accuracy = 0.44791\n",
            "Stop training because you reached max_epochs = 189 with best_epoch = 141 and best_val_0_balanced_accuracy = 0.52732\n",
            "\n",
            "Early stopping occurred at epoch 138 with best_epoch = 38 and best_val_0_balanced_accuracy = 0.40674\n",
            "Stop training because you reached max_epochs = 189 with best_epoch = 174 and best_val_0_balanced_accuracy = 0.4406\n",
            "Stop training because you reached max_epochs = 189 with best_epoch = 108 and best_val_0_balanced_accuracy = 0.45812\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 04:13:40,625] Trial 19 finished with value: 0.4595222724338283 and parameters: {'n_d': 16, 'n_a': 32, 'n_steps': 4, 'gamma': 1.4069104115452704, 'mask_type': 'sparsemax', 'batch_size': 128, 'max_epochs': 189}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 147 with best_epoch = 129 and best_val_0_balanced_accuracy = 0.4668\n",
            "Stop training because you reached max_epochs = 147 with best_epoch = 115 and best_val_0_balanced_accuracy = 0.55413\n",
            "Stop training because you reached max_epochs = 147 with best_epoch = 119 and best_val_0_balanced_accuracy = 0.43235\n",
            "Stop training because you reached max_epochs = 147 with best_epoch = 56 and best_val_0_balanced_accuracy = 0.4487\n",
            "Stop training because you reached max_epochs = 147 with best_epoch = 118 and best_val_0_balanced_accuracy = 0.46553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-02 05:04:00,490] Trial 20 finished with value: 0.4704970948999354 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.2551219672660037, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 147}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 184 with best_epoch = 136 and best_val_0_balanced_accuracy = 0.45113\n",
            "Stop training because you reached max_epochs = 184 with best_epoch = 132 and best_val_0_balanced_accuracy = 0.56093\n",
            "\n",
            "Early stopping occurred at epoch 126 with best_epoch = 26 and best_val_0_balanced_accuracy = 0.40581\n",
            "\n",
            "Early stopping occurred at epoch 177 with best_epoch = 77 and best_val_0_balanced_accuracy = 0.44519\n",
            "Stop training because you reached max_epochs = 184 with best_epoch = 94 and best_val_0_balanced_accuracy = 0.48874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-07-02 06:05:47,380] Trial 21 finished with value: 0.4605551969012266 and parameters: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.3705088397310103, 'mask_type': 'sparsemax', 'batch_size': 32, 'max_epochs': 184}. Best is trial 15 with value: 0.48160103292446743.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 187 with best_epoch = 105 and best_val_0_balanced_accuracy = 0.46467\n",
            "Stop training because you reached max_epochs = 187 with best_epoch = 171 and best_val_0_balanced_accuracy = 0.54002\n",
            "\n",
            "Early stopping occurred at epoch 119 with best_epoch = 19 and best_val_0_balanced_accuracy = 0.41751\n",
            "Stop training because you reached max_epochs = 187 with best_epoch = 90 and best_val_0_balanced_accuracy = 0.45649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FCJo8IYkfYQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zk1cnCeFfYON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}