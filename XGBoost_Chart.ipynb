{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b5873e3-2320-4316-8675-4c3f337fe4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import random \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import pickle \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from ts2vec import TS2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a03053b-1cd0-49a7-a500-e1cbc6225077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_data(chart_df, threshold=0.0075, lookback=16): \n",
    "    targets = [] \n",
    "    openv = chart_df[\"open\"].values \n",
    "    close = chart_df[\"close\"].values \n",
    "    high = chart_df[\"high\"].values \n",
    "    low = chart_df[\"low\"].values  \n",
    "    volume = chart_df[\"volume\"].values \n",
    "    \n",
    "    for i in range(close.shape[0]-1):\n",
    "        high_vol = (high[i+1] - close[i]) / close[i] \n",
    "        low_vol = (low[i+1] - close[i]) / close[i] \n",
    "        if high_vol >= threshold: \n",
    "            targets.append(0) \n",
    "        elif low_vol <= -threshold:\n",
    "            targets.append(1) \n",
    "        else:\n",
    "            targets.append(2) \n",
    "    targets.append(None) \n",
    "    chart_df[\"Targets\"] = targets \n",
    "    \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "    chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "    chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "    \n",
    "    chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "    chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "    chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "    chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "    chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"] \n",
    "    chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"]     \n",
    "    \n",
    "    for l in range(1, lookback): \n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "            val = chart_df[col].values \n",
    "            val_ret = [None for _ in range(l)]\n",
    "            for i in range(l, len(val)):\n",
    "                if val[i-l] == 0: \n",
    "                    ret = 1 \n",
    "                else:\n",
    "                    ret = val[i] / val[i-l]  \n",
    "                val_ret.append(ret) \n",
    "            chart_df[\"{}_change_{}\".format(col, l)] = val_ret \n",
    "\n",
    "    chart_df.dropna(inplace=True) \n",
    "    chart_df.drop(columns={\"open\", \"high\", \"low\", \"close\", \"volume\"}, inplace=True) \n",
    "    return chart_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5fb85e-aedd-4028-94c8-12a436d04bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf6abdf4f17467da4ecf415d5eca967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9608, 86) (1201, 86) (1202, 86)\n",
      "[07:59:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "lookback: 16\n",
      "accuracy : 54.0765391014975% | Macro F1 : 0.4915711345122425\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "accuracies, f1s = [], [] \n",
    "\n",
    "for lookback in tqdm(range(16, 17)): \n",
    "    df = pd.read_csv(\"updated.csv\") \n",
    "    df = preprocess_seq_data(df, threshold=0.0075, lookback=lookback)\n",
    "    train_columns = []\n",
    "    for col in df.columns:\n",
    "        if col not in [\"Targets\", \"datetime\", \"years\"]:\n",
    "            train_columns.append(col)  \n",
    "\n",
    "    X = df[train_columns] \n",
    "    Y = df[\"Targets\"] \n",
    "    \n",
    "    train_size = int(df.shape[0] * 0.8) \n",
    "    val_size = int(df.shape[0] * 0.1) \n",
    "\n",
    "    X_train = X.iloc[:train_size] \n",
    "    Y_train = Y.iloc[:train_size] \n",
    "\n",
    "    X_val = X.iloc[train_size:train_size+val_size] \n",
    "    Y_val = Y.iloc[train_size:train_size+val_size] \n",
    "\n",
    "    X_test = X.iloc[train_size+val_size:] \n",
    "    Y_test = Y.iloc[train_size+val_size:] \n",
    "    \n",
    "    print(X_train.shape, X_val.shape, X_test.shape)\n",
    "        \n",
    "    d = compute_class_weight(class_weight=\"balanced\", classes=np.unique(Y_train), y=Y_train) \n",
    "    clf = XGBClassifier(silent=False, \n",
    "                        n_estimators=200,\n",
    "                        class_weight=d, \n",
    "                        metric=\"logloss\",\n",
    "                        tree_method=\"gpu_hist\", \n",
    "                        max_depth=3)\n",
    "    clf.fit(X_train, \n",
    "            Y_train, \n",
    "            eval_set=[(X_val, Y_val)],\n",
    "            eval_metric=\"auc\",\n",
    "            verbose=0)\n",
    "\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    cnt = 0 \n",
    "    for i in range(len(Y_pred)): \n",
    "        if Y_pred[i] == Y_test[i]: \n",
    "            cnt += 1 \n",
    "\n",
    "    accuracy = cnt / len(Y_pred) * 100\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"macro\") \n",
    "\n",
    "    print(f\"lookback: {lookback}\")\n",
    "    print(f\"accuracy : {accuracy}% | Macro F1 : {f1}\")  \n",
    "    print(\"=\"*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5413f655-d454-4eb8-aa46-e18ba86e0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model(\"XGBoost_54_49\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10861111-2c80-4e5a-a6e0-4c39555c2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example load \n",
    "\n",
    "clf_load = XGBClassifier() \n",
    "clf_load.load_model(\"XGBoost_54_49\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90e7aa-2c90-49e4-894d-e0ee8aed03a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e8f59-32b3-4d93-bed2-cd9a6d02c8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427acbe-8d04-42b0-b824-30726b205837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228e242-0d87-4269-b404-dd12455fe236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528af83-2045-4716-a09b-134ddcbdbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c358e-5c2e-4524-b5f6-a64a6d27e0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
