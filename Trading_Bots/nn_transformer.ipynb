{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1c6de1-78b9-4f47-ad63-d7804028c8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install ccxt \\n!pip install transformers \\n!pip install lightgbm \\n!pip install pandas-ta \\n!pip install seaborn\\n!pip install --upgrade twisted \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install ccxt \n",
    "!pip install transformers \n",
    "!pip install lightgbm \n",
    "!pip install pandas-ta \n",
    "!pip install seaborn\n",
    "!pip install --upgrade twisted \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0c0380-fe3f-44d0-a87b-b5393bbfe47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "import ccxt \n",
    "from tqdm.auto import tqdm\n",
    "import pandas_ta as ta\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score \n",
    "import lightgbm as lgbm  \n",
    "\n",
    "# import libraries for NN \n",
    "import random \n",
    "import torch \n",
    "from torch import Tensor \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler, IterableDataset  \n",
    "from tqdm.auto import tqdm  \n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AdamW, get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317fcea7-373c-40b4-bbb9-730c7dc80b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000): \n",
    "        super(PositionalEncoding, self).__init__() \n",
    "        self.dropout = nn.Dropout(p=dropout) \n",
    "        pe = torch.zeros(max_len, d_model) \n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) \n",
    "        pe[:, 0::2] = torch.sin(position * div_term) \n",
    "        pe[:, 1::2] = torch.cos(position * div_term) \n",
    "        pe = pe.unsqueeze(0).transpose(0,1) \n",
    "        self.register_buffer(\"pe\", pe) \n",
    "    def forward(self, x): \n",
    "        x = x + self.pe[:x.size(0), :] \n",
    "        return self.dropout(x) \n",
    "\n",
    "class MultiSampleDropout(nn.Module): \n",
    "    def __init__(self, max_dropout_rate, num_samples, classifier): \n",
    "        super(MultiSampleDropout, self).__init__() \n",
    "        self.dropout = nn.Dropout \n",
    "        self.classifier = classifier \n",
    "        self.max_dropout_rate = max_dropout_rate \n",
    "        self.num_samples = num_samples \n",
    "    def forward(self, out): \n",
    "        return torch.mean(torch.stack([self.classifier(self.dropout(p=self.max_dropout_rate)(out)) for _, rate in enumerate(np.linspace(0, self.max_dropout_rate, self.num_samples))], dim=0), dim=0)\n",
    "\n",
    "class AttentivePooling(torch.nn.Module): \n",
    "    def __init__(self, input_dim): \n",
    "        super(AttentivePooling, self).__init__() \n",
    "        self.W = nn.Linear(input_dim, 1) \n",
    "    def forward(self, x): \n",
    "        softmax = F.softmax \n",
    "        att_w = softmax(self.W(x).squeeze(-1)).unsqueeze(-1) \n",
    "        x = torch.sum(x * att_w, dim=1) \n",
    "        return x \n",
    "\n",
    "class NeuralCLF(nn.Module): \n",
    "    def __init__(self, chart_features, sequence_length, d_model, num_classes, n_heads, num_encoders): \n",
    "        super(NeuralCLF, self).__init__() \n",
    "        self.chart_features = chart_features \n",
    "        self.sequence_length = sequence_length  \n",
    "        self.d_model = d_model \n",
    "        self.num_classes = num_classes  \n",
    "        self.n_heads = n_heads \n",
    "        self.num_encoders = num_encoders \n",
    "        self.chart_embedder = nn.Sequential(\n",
    "            nn.Linear(self.chart_features, d_model//2), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(d_model//2, d_model) \n",
    "        ) \n",
    "        self.pos_encoder = PositionalEncoding(d_model=self.d_model) \n",
    "        self.encoder_layers = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.n_heads, batch_first=True) \n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layers, num_layers=self.num_encoders) \n",
    "        self.attentive_pooling = AttentivePooling(input_dim=self.d_model)   \n",
    "        self.fc = nn.Linear(self.d_model, self.num_classes) \n",
    "        self.multi_dropout = MultiSampleDropout(0.2, 8, self.fc) \n",
    "    def forward(self, x): \n",
    "        x = self.chart_embedder(x)\n",
    "        x = self.pos_encoder(x) \n",
    "        x = self.transformer_encoder(x) \n",
    "        x = self.attentive_pooling(x) \n",
    "        x = self.multi_dropout(x)  \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75677a5b-0f5f-43f2-9023-59ca5f122d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedFocalLoss(nn.Module): \n",
    "    def __init__(self, alpha, gamma=2):\n",
    "        super(WeightedFocalLoss, self).__init__() \n",
    "        self.alpha = alpha \n",
    "        self.device = torch.device(\"cuda\") \n",
    "        self.alpha = self.alpha.to(self.device) \n",
    "        self.gamma = gamma \n",
    "    def forward(self, inputs, targets): \n",
    "        CE_loss = nn.CrossEntropyLoss()(inputs, targets) \n",
    "        targets = targets.type(torch.long) \n",
    "        at = self.alpha.gather(0, targets.data.view(-1)) \n",
    "        pt = torch.exp(-CE_loss) \n",
    "        F_loss = at * (1-pt)**self.gamma * CE_loss \n",
    "        return F_loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff54c7f-cc34-40bc-9aa3-93584684e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels): \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten() \n",
    "    labels_flat = labels.flatten() \n",
    "    return np.sum(pred_flat==labels_flat) / len(labels_flat) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59a92a-6860-4344-b0ca-06401ef6ef9f",
   "metadata": {},
   "source": [
    "### Train High Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bedc26b-ff49-4142-906d-7f62c8e16229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258224f58cec4839aa8630779de638ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('BTC_USDT-15m-4.json') as f:\n",
    "    d = json.load(f)\n",
    "    \n",
    "chart_df = pd.DataFrame(d)\n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\",\n",
    "                                    1:\"open\",\n",
    "                                    2:\"high\",\n",
    "                                    3:\"low\",\n",
    "                                    4:\"close\",\n",
    "                                    5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "    binance = ccxt.binance() \n",
    "    dates = df['timestamp'].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)): \n",
    "        date_string = binance.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string) \n",
    "    df['datetime'] = timestamp \n",
    "    df = df.drop(columns={'timestamp'})\n",
    "    return df\n",
    "\n",
    "chart_df = process(chart_df)\n",
    "\n",
    "minutes = [] \n",
    "hours = []\n",
    "days = [] \n",
    "months = [] \n",
    "years = [] \n",
    "for dt in tqdm(chart_df['datetime']): \n",
    "    minute = pd.to_datetime(dt).minute \n",
    "    hour = pd.to_datetime(dt).hour \n",
    "    day = pd.to_datetime(dt).day \n",
    "    month = pd.to_datetime(dt).month \n",
    "    year = pd.to_datetime(dt).year  \n",
    "    minutes.append(minute) \n",
    "    hours.append(hour) \n",
    "    days.append(day) \n",
    "    months.append(month)\n",
    "    years.append(year) \n",
    "\n",
    "chart_df[\"minute\"] = minutes \n",
    "chart_df['hour'] = hours\n",
    "chart_df['day'] = days \n",
    "chart_df['month'] = months \n",
    "chart_df['year'] = years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e4e199-d7d8-465a-911a-2ae1e5799bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d1f2aa8dc34dd0b922e3c8252090a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_open, p_high, p_low, p_close, p_volume = [], [], [], [], [] \n",
    "p_dt, p_minute, p_hour, p_day, p_month, p_year = [], [], [], [], [], [] \n",
    "\n",
    "for i in tqdm(range(chart_df.shape[0] - 16), position=0, leave=True): \n",
    "    segment = chart_df.iloc[i:i+16] \n",
    "    open_val = segment[\"open\"].values[0] \n",
    "    high_val = np.max(segment[\"high\"].values) \n",
    "    low_val = np.min(segment[\"low\"].values) \n",
    "    close_val = segment[\"close\"].values[-1] \n",
    "    volume_val = np.sum(segment[\"volume\"].values) \n",
    "    \n",
    "    dt_val = segment[\"datetime\"].values[0] \n",
    "    minute_val = segment[\"minute\"].values[0] \n",
    "    hour_val = segment[\"hour\"].values[0] \n",
    "    day_val = segment[\"day\"].values[0] \n",
    "    month_val = segment[\"month\"].values[0] \n",
    "    year_val = segment[\"year\"].values[0] \n",
    "    \n",
    "    p_open.append(open_val) \n",
    "    p_high.append(high_val) \n",
    "    p_low.append(low_val) \n",
    "    p_close.append(close_val) \n",
    "    p_volume.append(volume_val) \n",
    "    p_dt.append(dt_val) \n",
    "    p_minute.append(minute_val) \n",
    "    p_hour.append(hour_val) \n",
    "    p_day.append(day_val) \n",
    "    p_month.append(month_val)\n",
    "    p_year.append(year_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91db8790-0b5d-4966-9d87-ddaef98fe503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4261.32</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>82.088865</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>4377.85</td>\n",
       "      <td>4261.32</td>\n",
       "      <td>4360.71</td>\n",
       "      <td>80.666221</td>\n",
       "      <td>2017-08-17 04:15:00</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4280.00</td>\n",
       "      <td>4377.85</td>\n",
       "      <td>4267.99</td>\n",
       "      <td>4360.70</td>\n",
       "      <td>71.622199</td>\n",
       "      <td>2017-08-17 04:30:00</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4310.07</td>\n",
       "      <td>4377.85</td>\n",
       "      <td>4287.41</td>\n",
       "      <td>4360.69</td>\n",
       "      <td>49.797909</td>\n",
       "      <td>2017-08-17 04:45:00</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4308.83</td>\n",
       "      <td>4377.85</td>\n",
       "      <td>4287.41</td>\n",
       "      <td>4360.69</td>\n",
       "      <td>35.880663</td>\n",
       "      <td>2017-08-17 05:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open     high      low    close     volume             datetime  minute  \\\n",
       "0  4261.48  4349.99  4261.32  4349.99  82.088865  2017-08-17 04:00:00       0   \n",
       "1  4261.48  4377.85  4261.32  4360.71  80.666221  2017-08-17 04:15:00      15   \n",
       "2  4280.00  4377.85  4267.99  4360.70  71.622199  2017-08-17 04:30:00      30   \n",
       "3  4310.07  4377.85  4287.41  4360.69  49.797909  2017-08-17 04:45:00      45   \n",
       "4  4308.83  4377.85  4287.41  4360.69  35.880663  2017-08-17 05:00:00       0   \n",
       "\n",
       "   hour  day  month  year  \n",
       "0     4   17      8  2017  \n",
       "1     4   17      8  2017  \n",
       "2     4   17      8  2017  \n",
       "3     4   17      8  2017  \n",
       "4     5   17      8  2017  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_chart_df = pd.DataFrame(list(zip(p_open, p_high, p_low, p_close, p_volume, p_dt, p_minute, p_hour, p_day, p_month, p_year)), \n",
    "                             columns=[\"open\",\"high\",\"low\",\"close\",\"volume\",\"datetime\",\"minute\",\"hour\",\"day\",\"month\",\"year\"])\n",
    "                             \n",
    "four_chart_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01f67d1-6d70-4ef6-92db-d7b7f959f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((181982, 11), (181966, 11))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_df.shape, four_chart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a3ccd17-450e-475e-9426-cd5d92d1032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d46863107a4323875f530de267b246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = [] \n",
    "\n",
    "for i in tqdm(range(16), position=0, leave=True): \n",
    "    dfs.append(four_chart_df.iloc[i::16]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d22e960e-ab4b-469a-8dc1-7fea2be073c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_data(chart_df, target=\"high\", threshold=0.0075): \n",
    "    targets = [] \n",
    "    openv = chart_df[\"open\"].values \n",
    "    close = chart_df[\"close\"].values \n",
    "    high = chart_df[\"high\"].values \n",
    "    low = chart_df[\"low\"].values  \n",
    "    volume = chart_df[\"volume\"].values \n",
    "    \n",
    "    if target == \"high\":\n",
    "        for i in range(close.shape[0]-1):\n",
    "            high_vol = (high[i+1] - close[i]) / close[i] \n",
    "            if high_vol >= threshold: \n",
    "                targets.append(1) \n",
    "            else: \n",
    "                targets.append(0) \n",
    "    elif target == \"low\": \n",
    "        for i in range(close.shape[0]-1):\n",
    "            low_vol = (low[i+1] - close[i]) / close[i] \n",
    "            if low_vol <= -threshold: \n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0) \n",
    "    targets.append(None) \n",
    "    chart_df[\"Targets\"] = targets \n",
    "    \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "    chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "    chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False) \n",
    "    chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "    chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
    "    chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "    chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "    chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "    chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "    chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"] \n",
    "    chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"] \n",
    "    \n",
    "    ratio_open = [None] \n",
    "    ratio_close = [None] \n",
    "    ratio_high = [None] \n",
    "    ratio_low = [None] \n",
    "    ratio_volume = [None] \n",
    "    for i in range(1, len(openv)): \n",
    "        r_open = openv[i] / openv[i-1] \n",
    "        r_close = close[i] / close[i-1] \n",
    "        r_high = high[i] / high[i-1] \n",
    "        r_low = low[i] / low[i-1] \n",
    "        if volume[i-1] == 0: \n",
    "            r_vol = 1 \n",
    "        else:\n",
    "            r_vol = volume[i] / volume[i-1]\n",
    "        ratio_open.append(r_open) \n",
    "        ratio_close.append(r_close) \n",
    "        ratio_high.append(r_high) \n",
    "        ratio_low.append(r_low) \n",
    "        ratio_volume.append(r_vol) \n",
    "    \n",
    "    chart_df[\"r_open\"] = ratio_open \n",
    "    chart_df[\"r_close\"] = ratio_close \n",
    "    chart_df[\"r_high\"] = ratio_high \n",
    "    chart_df[\"r_low\"] = ratio_low \n",
    "    chart_df[\"r_volume\"] = ratio_volume \n",
    "    chart_df.dropna(inplace=True) \n",
    "    return chart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4c270d3-5d34-4853-83fe-75c0d18729e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f2e700337d4e26be69ab61ff03a6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106/1313806058.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"Targets\"] = targets\n",
      "/tmp/ipykernel_106/1313806058.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False)\n",
      "/tmp/ipykernel_106/1313806058.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False)\n",
      "/tmp/ipykernel_106/1313806058.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False)\n",
      "/tmp/ipykernel_106/1313806058.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
      "/tmp/ipykernel_106/1313806058.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"]\n",
      "/tmp/ipykernel_106/1313806058.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"]\n",
      "/tmp/ipykernel_106/1313806058.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"]\n",
      "/tmp/ipykernel_106/1313806058.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"]\n",
      "/tmp/ipykernel_106/1313806058.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"]\n",
      "/tmp/ipykernel_106/1313806058.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"]\n",
      "/tmp/ipykernel_106/1313806058.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"r_open\"] = ratio_open\n",
      "/tmp/ipykernel_106/1313806058.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"r_close\"] = ratio_close\n",
      "/tmp/ipykernel_106/1313806058.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"r_high\"] = ratio_high\n",
      "/tmp/ipykernel_106/1313806058.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"r_low\"] = ratio_low\n",
      "/tmp/ipykernel_106/1313806058.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chart_df[\"r_volume\"] = ratio_volume\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "processed_charts = [] \n",
    "\n",
    "for df in tqdm(dfs):\n",
    "    processed_df = preprocess_seq_data(df) \n",
    "    processed_charts.append(processed_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c33c9ec2-e160-4f6d-9014-b85ee77076c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = [] \n",
    "\n",
    "for i in range(len(processed_charts)): \n",
    "    X.append(processed_charts[i][[\"bop\", \"ebsw\", \"cmf\", \"rsi/100\", \"r_open\", \"r_close\", \"r_high\", \"r_low\", \"r_volume\", \"high/low\", \"high/open\", \"low/open\", \"close/open\", \n",
    "                                  \"high/close\", \"low/close\"]])\n",
    "    Y.append(processed_charts[i][[\"Targets\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb8af732-37e7-4a4a-8a67-d9cb638aa99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a576e65ce1549c58ddbcf6a4df0b86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = 42\n",
    "\n",
    "X_train, X_val, X_test = [], [], [] \n",
    "Y_train, Y_val, Y_test = [], [], [] \n",
    "\n",
    "for i in tqdm(range(len(processed_charts))): \n",
    "    cur_X = X[i] \n",
    "    cur_Y = Y[i] \n",
    "    X_seq, Y_labels = [], [] \n",
    "    for j in range(cur_X.shape[0]-seq_len): \n",
    "        X_seq.append(cur_X.iloc[j:j+seq_len].values) \n",
    "        Y_labels.append(cur_Y.iloc[j+seq_len-1].values[0]) \n",
    "    \n",
    "    train_size = int(0.8 * len(X_seq)) \n",
    "    val_size = int(0.1 * len(X_seq)) \n",
    "    X_train.extend(X_seq[:train_size]) \n",
    "    Y_train.extend(Y_labels[:train_size]) \n",
    "    \n",
    "    X_val.extend(X_seq[train_size:train_size+val_size]) \n",
    "    Y_val.extend(Y_labels[train_size:train_size+val_size]) \n",
    "    \n",
    "    X_test.extend(X_seq[train_size+val_size:]) \n",
    "    Y_test.extend(Y_labels[train_size+val_size:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df0d4aae-f909-4a09-bca2-d0b4219d255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98446782, 1.01603015])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(Y_train), y=np.array(Y_train)) \n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f89a47e-5d9c-4d08-a0e7-bdd5bf759d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106/4030092549.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n",
      "  X_train = torch.tensor(X_train).float()\n",
      "/tmp/ipykernel_106/4030092549.py:2: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  Y_train = torch.tensor(Y_train, dtype=int)\n",
      "/tmp/ipykernel_106/4030092549.py:5: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  Y_val = torch.tensor(Y_val, dtype=int)\n",
      "/tmp/ipykernel_106/4030092549.py:8: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  Y_test = torch.tensor(Y_test, dtype=int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([144512, 42, 15]),\n",
       " torch.Size([144512]),\n",
       " torch.Size([18064, 42, 15]),\n",
       " torch.Size([18064]),\n",
       " torch.Size([18078, 42, 15]),\n",
       " torch.Size([18078]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train).float() \n",
    "Y_train = torch.tensor(Y_train, dtype=int) \n",
    "\n",
    "X_val = torch.tensor(X_val).float() \n",
    "Y_val = torch.tensor(Y_val, dtype=int) \n",
    "\n",
    "X_test = torch.tensor(X_test).float() \n",
    "Y_test = torch.tensor(Y_test, dtype=int) \n",
    "\n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f70eb710-5929-4ea2-a425-a51e32e3b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 \n",
    "\n",
    "train_data = TensorDataset(X_train, Y_train) \n",
    "train_sampler = RandomSampler(train_data) \n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) \n",
    "\n",
    "val_data = TensorDataset(X_val, Y_val) \n",
    "val_sampler = SequentialSampler(val_data) \n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size) \n",
    "\n",
    "test_data = TensorDataset(X_test, Y_test) \n",
    "test_sampler = SequentialSampler(test_data) \n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28a314cf-e61a-4d1e-9a0f-67dc1f13657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], [] \n",
    "train_accuracies, val_accuracies = [], [] \n",
    "\n",
    "device = torch.device(\"cuda\") \n",
    "model = NeuralCLF(chart_features=X_train.shape[2], sequence_length=X_train.shape[1], d_model=256, num_classes=2, n_heads=8, num_encoders=6) \n",
    "model.cuda() \n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8) \n",
    "epochs = 20  \n",
    "total_steps = len(train_dataloader) * epochs \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1*total_steps), num_training_steps=total_steps) \n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float) \n",
    "loss_func = WeightedFocalLoss(alpha=class_weights) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21ff1abc-96cb-44e1-b02b-97e6747129fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fe834ae6dd44e4840c6aa6734f33ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88eb43f10c14a4299bedceda8c96324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106/1265509206.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_w = softmax(self.W(x).squeeze(-1)).unsqueeze(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.18100434644559843\n",
      "average train accuracy : 0.5023506637168141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67650543ab9a41079fc2ab5129f879bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17419067822711568\n",
      "average val accuracy: 0.5098787167449139\n",
      "saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da240539f0a439997a3b42e0f187cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.17514571639816318\n",
      "average train accuracy : 0.5034499446902655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9e595da2af486fbebf7063c6961a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.1717812633010703\n",
      "average val accuracy: 0.5326682316118936\n",
      "saving best model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc94d2bae3624a17ad90df286fbee794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.17408974819478734\n",
      "average train accuracy : 0.5046805862831858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d4cabe888a4b25977dfe303d294869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17190403522739947\n",
      "average val accuracy: 0.5331939553990611\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d641c398fb420fb0d0cd4fdf093af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.17385032271916886\n",
      "average train accuracy : 0.5047566371681416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d315902643e34e59ba7c0f3097c574ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17235689452836211\n",
      "average val accuracy: 0.537014622456964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f4f260da0d4bedbe8aac62d48775d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.17346002211612938\n",
      "average train accuracy : 0.5081996681415929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ccd5a21da8401fb02254f10dfb0dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17422684355520865\n",
      "average val accuracy: 0.4870892018779343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3a4d61276b4cbfa7c5dbf4a86a24ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.17249244493720806\n",
      "average train accuracy : 0.5198700221238938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443d994eab2c4ffb8a53a58984eb1f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17273475733441365\n",
      "average val accuracy: 0.522801741001565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2b504f9278460b904b04c704233113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.16056530836936647\n",
      "average train accuracy : 0.5829300331858407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181b78eb812045d2bbb18b36376e55bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17488832687827902\n",
      "average val accuracy: 0.5485377543035994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cf42bf5e0243ab8d400652da054b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.15199977829393033\n",
      "average train accuracy : 0.6089670907079646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d63bc4fabe40a98727d4f2064f83ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.19412992831686854\n",
      "average val accuracy: 0.547633020344288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eea7d3aa9804189a453a45b9b6298fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.14976732566029624\n",
      "average train accuracy : 0.6162887168141593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6324a5bdbf4ed88f81c195a67584e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.174427394715833\n",
      "average val accuracy: 0.5558184174491393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a72de80caa44d5981ed8aaa5d0379d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.14810962717881246\n",
      "average train accuracy : 0.6192408738938053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b830910375a42cab5d7d91dc7911170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17321756629037185\n",
      "average val accuracy: 0.5560201486697965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3313317b504a3aae30ab113e431751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.1472362669695795\n",
      "average train accuracy : 0.6225525442477876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1837cbf4214046aa9a5d19a2a2614571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.18182640680125062\n",
      "average val accuracy: 0.5551215277777778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257874adbe014fe8a6218ab4bb5da5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.14637546752933908\n",
      "average train accuracy : 0.6238454092920354\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5186bd322291443ca4640c54e3fb18cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17751193634221252\n",
      "average val accuracy: 0.5582942097026604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46889983edf54cf897997d2924009b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.14549993703850603\n",
      "average train accuracy : 0.6262928650442477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026afdf83b3345c4999559854d701892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average val loss: 0.17531924936133372\n",
      "average val accuracy: 0.5612896126760564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c7864ab69045538489101848c1b21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch) \n\u001b[1;32m      9\u001b[0m b_seqs, b_labels \u001b[38;5;241m=\u001b[39m batch \n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_seqs\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, b_labels) \n\u001b[1;32m     12\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mNeuralCLF.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchart_embedder(x)\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(x) \n\u001b[0;32m---> 60\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     61\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattentive_pooling(x) \n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_dropout(x)  \n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/transformer.py:202\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    199\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 202\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/transformer.py:344\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training logic \n",
    "model.zero_grad() \n",
    "for epoch_i in tqdm(range(epochs), desc=\"Epochs\", position=0, leave=True, total=epochs): \n",
    "    train_loss, train_accuracy = 0, 0 \n",
    "    model.train() \n",
    "    with tqdm(train_dataloader, unit=\"batch\") as tepoch: \n",
    "        for step, batch in enumerate(tepoch): \n",
    "            batch = tuple(t.to(device) for t in batch) \n",
    "            b_seqs, b_labels = batch \n",
    "            outputs = model(b_seqs) \n",
    "            loss = loss_func(outputs, b_labels) \n",
    "            train_loss += loss.item() \n",
    "            logits_cpu, labels_cpu = outputs.detach().cpu().numpy(), b_labels.detach().cpu().numpy() \n",
    "            train_accuracy += flat_accuracy(logits_cpu, labels_cpu) \n",
    "            loss.backward() \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) \n",
    "            optimizer.step() \n",
    "            scheduler.step() \n",
    "            model.zero_grad() \n",
    "            tepoch.set_postfix(loss=train_loss / (step+1), accuracy=100.0 * train_accuracy / (step+1)) \n",
    "            time.sleep(0.1) \n",
    "        avg_train_loss = train_loss / len(train_dataloader) \n",
    "        avg_train_accuracy = train_accuracy / len(train_dataloader)  \n",
    "        train_losses.append(avg_train_loss) \n",
    "        train_accuracies.append(avg_train_accuracy) \n",
    "        print(f\"average train loss : {avg_train_loss}\") \n",
    "        print(f\"average train accuracy : {avg_train_accuracy}\") \n",
    "    val_loss, val_accuracy = 0, 0 \n",
    "    model.eval() \n",
    "    for step, batch in tqdm(enumerate(val_dataloader), position=0, leave=True, total=len(val_dataloader)): \n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_seqs, b_labels = batch \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(b_seqs) \n",
    "        loss = loss_func(outputs, b_labels) \n",
    "        val_loss += loss.item()\n",
    "        logits_cpu, labels_cpu = outputs.detach().cpu().numpy(), b_labels.detach().cpu().numpy() \n",
    "        val_accuracy += flat_accuracy(logits_cpu, labels_cpu) \n",
    "    avg_val_loss = val_loss / len(val_dataloader) \n",
    "    avg_val_accuracy = val_accuracy / len(val_dataloader) \n",
    "    val_losses.append(avg_val_loss) \n",
    "    val_accuracies.append(avg_val_accuracy) \n",
    "    print(f\"average val loss: {avg_val_loss}\") \n",
    "    print(f\"average val accuracy: {avg_val_accuracy}\") \n",
    "    print(\"saving current checkpoint...\") \n",
    "    torch.save(model.state_dict(), f\"TFNet_CLF_val_acc:{avg_val_accuracy}_val_loss:{avg_val_loss}.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56f0ff-830f-480f-826d-a24e949470e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model performance \n",
    "# check performance on test set \n",
    "model = NeuralCLF(chart_features=X_train.shape[2], sequence_length=X_train.shape[1], d_model=256, num_classes=2, n_heads=8, num_encoders=6) \n",
    "checkpoint = torch.load(\"\") \n",
    "best_model.load_state_dict(checkpoint) \n",
    "best_model.cuda() \n",
    "best_model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d3a655f-4594-4b2e-a30b-5aac4a390cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559e4c6d74634d1faa4696ce40f0ba86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106/1265509206.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_w = softmax(self.W(x).squeeze(-1)).unsqueeze(-1)\n"
     ]
    }
   ],
   "source": [
    "pred_classes = [] \n",
    "model.eval() \n",
    "for step, batch in tqdm(enumerate(test_dataloader), desc=\"Testing\", position=0, leave=True, total=len(test_dataloader)): \n",
    "    batch = tuple(t.to(device) for t in batch) \n",
    "    b_seqs, b_labels = batch \n",
    "    with torch.no_grad(): \n",
    "        output = model(b_seqs) \n",
    "        \n",
    "    pred_class = torch.argmax(output, dim=1)  \n",
    "    pred_classes.extend(pred_class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f44c3da-6fd7-4477-9e6d-e359026ba2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy = 58.856068149131545\n",
      "model F1 = 0.4229635376260667\n",
      "only zero agent = 56.04602279013166\n",
      "only one agent = 43.95397720986835\n"
     ]
    }
   ],
   "source": [
    "pred_classes_cpu = [] \n",
    "for p in pred_classes:\n",
    "    pred_classes_cpu.append(p.detach().cpu()) \n",
    "\n",
    "cnt = 0 \n",
    "for i in range(len(Y_test)): \n",
    "    if Y_test[i] == pred_classes_cpu[i]:  \n",
    "        cnt += 1 \n",
    "        \n",
    "only_zero = 0 \n",
    "only_one = 0 \n",
    "for i in range(len(Y_test)): \n",
    "    if Y_test[i] == 0: \n",
    "        only_zero += 1 \n",
    "    if Y_test[i] == 1: \n",
    "        only_one += 1 \n",
    "\n",
    "print(f\"model accuracy = {cnt/len(Y_test)*100}\")  \n",
    "print(f\"model F1 = {f1_score(Y_test, pred_classes_cpu)}\") \n",
    "print(f\"only zero agent = {only_zero/len(Y_test)*100}\") \n",
    "print(f\"only one agent = {only_one/len(Y_test)*100}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08e00b5e-8121-4138-b00b-0406f4b39a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"TFNet_CLF_test_acc_58.856.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e477bb-751b-4ab0-948a-cf3be94204e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
