{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd6735d-aa80-4bd2-9232-18e5e529fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm \n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ccxt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score \n",
    "import pandas_ta as ta\n",
    "from xgboost import XGBClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d277c05-b0a8-4332-bcfe-7f6eca7fe2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_df = pd.read_csv(\"chart_df_with_deberta_sentiments.csv\") \n",
    "targets = [] \n",
    "high = chart_df[\"high\"].values \n",
    "low = chart_df[\"low\"].values \n",
    "close = chart_df[\"close\"].values \n",
    "\n",
    "threshold = 0.01 \n",
    "\n",
    "for i in range(len(close)-1):\n",
    "    high_vol = (high[i+1] - close[i]) / close[i] \n",
    "    low_vol = (low[i+1] - close[i]) / close[i] \n",
    "    if high_vol >= threshold: \n",
    "        targets.append(0) \n",
    "    elif low_vol <= -threshold:\n",
    "        targets.append(1) \n",
    "    else:\n",
    "        targets.append(2) \n",
    "        \n",
    "targets.append(None) \n",
    "\n",
    "chart_df[\"Targets\"] = targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14da9d2c-4239-4668-bdc8-9f15170472ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 36.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10929, 63)\n"
     ]
    }
   ],
   "source": [
    "chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "\n",
    "### addition of chart features ### \n",
    "chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False) \n",
    "chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "chart_df[\"vwap\"] = chart_df.ta.vwap(lookahead=False) \n",
    "chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
    "chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "chart_df[\"hwma\"] = chart_df.ta.hwma(lookahead=False) \n",
    "chart_df[\"linreg\"] = chart_df.ta.linreg(lookahead=False) \n",
    "chart_df[\"hwma/close\"] = chart_df[\"hwma\"] / chart_df[\"close\"] \n",
    "chart_df[\"linreg/close\"] = chart_df[\"linreg\"] / chart_df[\"close\"]\n",
    "chart_df[\"sma\"] = chart_df.ta.sma(lookahead=False) \n",
    "chart_df[\"sma/close\"] = chart_df[\"sma\"] / chart_df[\"close\"] \n",
    "\n",
    "\n",
    "### addition of recent differenced features ### \n",
    "for l in tqdm(range(1, 12), position=0, leave=True): \n",
    "    for col in [\"high\", \"low\", \"volume\", \"vwap\"]:\n",
    "        val = chart_df[col].values \n",
    "        val_ret = [None for _ in range(l)]\n",
    "        for i in range(l, len(val)):\n",
    "            if val[i-l] == 0: \n",
    "                ret = 1 \n",
    "            else:\n",
    "                ret = val[i] / val[i-l]  \n",
    "            val_ret.append(ret) \n",
    "        chart_df[\"{}_change_{}\".format(col, l)] = val_ret\n",
    "        \n",
    "### drop unnecessary columns ### \n",
    "chart_df.drop(columns={\"open\",\"high\",\"low\",\"close\",\"volume\",\"vwap\",\"hwma\",\"linreg\", \"sma\"}, inplace=True) \n",
    "\n",
    "\n",
    "chart_df.dropna(inplace=True)\n",
    "\n",
    "print(chart_df.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d82bcc5f-adcf-4107-a2f9-baecf66150fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8743, 63), (1092, 63), (1094, 63))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = chart_df.columns \n",
    "\n",
    "train_columns = [] \n",
    "\n",
    "for c in columns:\n",
    "    if c not in [\"year\",\"datetime\",\"Targets\"]: \n",
    "        train_columns.append(c) \n",
    "        \n",
    "        \n",
    "train_idx = int(chart_df.shape[0] * 0.8) \n",
    "val_idx = int(chart_df.shape[0] * 0.1)\n",
    "train_df, val_df, test_df = chart_df.iloc[:train_idx], chart_df.iloc[train_idx:train_idx+val_idx], chart_df.iloc[train_idx+val_idx:]\n",
    "\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4bc1d74-5d0b-438b-a5a6-7faefac1cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8696906396100667, 1: 1.2178576403398802, 2: 0.9717683672335223}\n"
     ]
    }
   ],
   "source": [
    "chart_df.dropna(inplace=True)\n",
    "X_train = train_df[train_columns] \n",
    "Y_train = train_df[\"Targets\"]\n",
    "\n",
    "X_val = val_df[train_columns] \n",
    "Y_val = val_df[\"Targets\"] \n",
    "\n",
    "X_test = test_df[train_columns] \n",
    "Y_test = test_df[\"Targets\"] \n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",\n",
    "                                     classes = np.unique(Y_train),\n",
    "                                     y = Y_train) \n",
    "\n",
    "d = {0:class_weights[0], 1:class_weights[1], 2:class_weights[2]} \n",
    "\n",
    "print(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55bc0c39-59cc-4115-bbaf-84dac8b8bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14586\n",
      "[LightGBM] [Info] Number of data points in the train set: 8743, number of used features: 60\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[20]\tvalid_0's multi_logloss: 1.0868\n",
      "[40]\tvalid_0's multi_logloss: 1.09756\n",
      "[60]\tvalid_0's multi_logloss: 1.10619\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 1.11383\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 1.12172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\tvalid_0's multi_logloss: 1.13043\n",
      "[140]\tvalid_0's multi_logloss: 1.1365\n",
      "[160]\tvalid_0's multi_logloss: 1.14343\n",
      "[180]\tvalid_0's multi_logloss: 1.15174\n",
      "[200]\tvalid_0's multi_logloss: 1.15917\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight={0: 0.8696906396100667, 1: 1.2178576403398802,\n",
       "                             2: 0.9717683672335223},\n",
       "               max_depth=12, metric=&#x27;multi_logloss&#x27;, n_estimators=200,\n",
       "               num_class=3, objective=&#x27;multiclass&#x27;, silent=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight={0: 0.8696906396100667, 1: 1.2178576403398802,\n",
       "                             2: 0.9717683672335223},\n",
       "               max_depth=12, metric=&#x27;multi_logloss&#x27;, n_estimators=200,\n",
       "               num_class=3, objective=&#x27;multiclass&#x27;, silent=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight={0: 0.8696906396100667, 1: 1.2178576403398802,\n",
       "                             2: 0.9717683672335223},\n",
       "               max_depth=12, metric='multi_logloss', n_estimators=200,\n",
       "               num_class=3, objective='multiclass', silent=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgbm.LGBMClassifier(silent=False, \n",
    "                          n_estimators=200,\n",
    "                          class_weight=d, \n",
    "                          objective=\"multiclass\",\n",
    "                          metric=\"multi_logloss\", \n",
    "                          max_depth=12,\n",
    "                          num_class=3)\n",
    "\n",
    "clf.fit(X_train, \n",
    "        Y_train, \n",
    "        eval_set=[(X_val, Y_val)],\n",
    "        verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c712fe4f-3b13-4969-819f-2ba764de24b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 46.61791590493601%\n"
     ]
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test) \n",
    "cnt = 0 \n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_test.values[i]:\n",
    "        cnt += 1 \n",
    "        \n",
    "print(\"accuracy = {}%\".format(cnt / len(Y_pred) * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2b077c0-e10d-4145-b6ab-62db4b0351ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45446965479574986"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, Y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0f6ec31-0b8e-4671-b822-5ef628d63fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier() \n",
    "xgb.load_model(\"xgboost_btc_3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a0cae6a-1bb1-46b5-af1e-55ab1bc6a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_prob = clf.predict_proba(X_test)\n",
    "xgb_prob = xgb.predict_proba(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e2c71a7-2b89-49f8-a939-367cbbc955de",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prob = (lgbm_prob + xgb_prob) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f39fc151-c429-4c5d-875b-fbe4e0c00f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(avg_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "598b1e09-eb87-497c-af52-c82d781338a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 47.98903107861061%\n"
     ]
    }
   ],
   "source": [
    "cnt = 0 \n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_test.values[i]:\n",
    "        cnt += 1 \n",
    "        \n",
    "print(\"accuracy = {}%\".format(cnt / len(Y_pred) * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fef3e36-e01c-4812-9d8a-05e48d44b722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4598453895536625"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, Y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4629718-dd33-4fad-a490-17760335774d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
