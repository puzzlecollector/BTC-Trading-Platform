목표: 주어진 데이터셋에서 베이스라인인 MBHN 모델보다 성능이 우수한 모델을 제시하는것. 

지금 실험중인것: encoder-only 방식 

chart encoder가 lookback tau만큼의 차트 데이터를 입력으로 받고 chart embedding 생성 
tweet encoder가 오늘 나온 트윗들을 입력으로 받고 트윗들의 text embedidng 생성 
이 두 임베딩을 합한 후, linear layer를 통과해서 예측값 계산. 
이때 look forward window (예측하는 기간)이 T라고하면, T개의 서로 다른 classification head들이 학습된다. 현재 타임스텝이 t라고하면, i (1 <= i <= T)번째 classification head는 t+i가 bubble일지 아닐지 예측한다. 

차트 데이터 (일봉이다) 전처리는 open, high, low, close, volumefrom_x, volumeto_x의 ratio가 사용된다 (i.e. open_{t} / open_{t-1}). 여기에 추가적으로 open, high, low, close를 이용해서 계산되는 고전 차트 지표들 (balance of power, even better sine wave, chaikin money flow, RSI) 를 추가한다. 
텍스트 데이터는 해당 날에 나온 모든 트윗을 이어붙혀서 하나의 긴 텍스트로 만든뒤에 이 텍스트를 LM에 넘겨준다. 

chart encoder 후보
1. Transformer  
2. Crypto BigBird (준영님의 차트 사전학습 모델) 

tweet encoder 후보 
1. ElKulako/cryptobert
2. vinai/bertweet-base 
3. google/bigbird-roberta-base (더 긴 시퀀스 4096 토큰을 입력으로 받을 수 있다)  

그래서 총 2*3 = 6개의 조합들로 실험하면 될 것 같다.  

lookback tau 값 후보: 1-20 
lookahead T 값 후보: 5, 10, 15, 20 
 
시간이 있으면 encoder-decoder 방식도 실험해볼 수 있을 것 같다. 이 방식은 T개의 classification head가 있는것이 아니라 chart embedding + text embedding 연산후에 계산된 벡터가 decoder로 넘어가서 T개의 입력을 생성해내는 방식이다. 

베이스라인 논문의 Table 5 (실험 결과)가 어떻게 계산되었는지 자세히 봐야겠지만 대략 F1, EM (accuracy) 0.53을 넘기고 MCC 0.25를 넘기면 되는것으로 보인다. 
손실함수는 논문에서 사용한것처럼 focal loss를 사용하는게 좋을 것 같다 (cross entropy를 사용해서 비교해봐도 된다). 

reddit 데이터에 대해서 논문이 한것처럼 제로샷 실험을 할 필요가 있을것으로 보인다. 

Encoder-only 구조만해도 괜찮을 것 같은데 완벽한 비교를 위해서 encoder-decoder구조가 더 좋을 것 같다.  
